{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40aa54e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input\\file1.txt  It is essential to develop non-precious metal-based alternatives used \n",
      "../files/input\\file2.txt  Electric vehicles are gaining global popularity lately, and along with\n",
      "../files/input\\file3.txt  Global solar irradiation is an important variable that can be used to \n"
     ]
    }
   ],
   "source": [
    "# Carga de datos\n",
    "import glob\n",
    "\n",
    "\n",
    "def load_data(input_directory):\n",
    "\n",
    "    sequence = []\n",
    "    files = glob.glob(f\"{input_directory}/*\")\n",
    "    for file in files:\n",
    "        with open(file, \"rt\", encoding=\"utf-8\") as f:\n",
    "            raw_text = f.read()\n",
    "            sequence.append((file, raw_text))\n",
    "    return sequence\n",
    "\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "for file, text in sequence:\n",
    "    print(f\"{file}  {text[:70]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d217599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input\\file1.txt  it is essential to develop non-precious metal-based alternatives used \n",
      "../files/input\\file2.txt  electric vehicles are gaining global popularity lately, and along with\n",
      "../files/input\\file3.txt  global solar irradiation is an important variable that can be used to \n"
     ]
    }
   ],
   "source": [
    "# Clean text\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_text(sequence):\n",
    "    cleaned_sequence = []\n",
    "    for file, text in sequence:\n",
    "        cleaned_text = re.sub(r\"\\n\", \" \", text)\n",
    "        cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text)\n",
    "        cleaned_text = cleaned_text.strip()\n",
    "        cleaned_text = cleaned_text.lower()\n",
    "        cleaned_sequence.append((file, cleaned_text))\n",
    "    return cleaned_sequence\n",
    "\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "for file, text in cleaned_sequence:\n",
    "    print(f\"{file}  {text[:70]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5932de3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input\\file1.txt  it is essential to develop non-precious metal-based alternatives used \n",
      "../files/input\\file2.txt  electric vehicles are gaining global popularity lately , and along wit\n",
      "../files/input\\file3.txt  global solar irradiation is an important variable that can be used to \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "\n",
    "def tokenize(sequence):\n",
    "    tokenized_sequence = []\n",
    "    for file, text in sequence:\n",
    "        tokens = word_tokenize(text)\n",
    "        tokenized_sequence.append((file, tokens))\n",
    "    return tokenized_sequence\n",
    "\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "tokenized_sequence = tokenize(cleaned_sequence)\n",
    "for file, text in tokenized_sequence:\n",
    "    print(f\"{file}  {' '.join(text)[:70]}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50dfafb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is essential to develop non-precious metal-based alternatives used\n",
      "in hydrogen evolution reaction ( her ) due to high cost and scarcity\n",
      "of pt-based catalysts . herein , through density functional theory (\n",
      "dft ) calculations , the her activity over 26 single-atom anchored\n",
      "phosphorus carbide ( pc3 ) monolayer ( tm @ pc3 ) has been\n",
      "systematically investigated . results indicate that δg * h of v , fe ,\n",
      "nb , mo , and pd @ pc3 are lower than that of pt ( 1 1 1 ) catalyst ,\n",
      "with 0.03 , −0.03 , −0.07 , −0.04 , and − 0.02 ev , respectively . by\n",
      "imposing the criterion window ( −0.2 ≤ δg * h ≤ 0.2 ev ) , the d band\n",
      "centre ( εd ) for catalysts with excellent her ability is in the range\n",
      "of − 0.68–0.41 ev . besides , the five promising her catalysts follow\n",
      "volmer-tafel mechanism . fe , nb , and mo @ pc3 show activation\n",
      "barriers of 0.75 , 0.74 , and 0.55 ev , lower than that of pt .\n",
      "machine learning ( ml ) was employed to explore the intrinsic\n",
      "relationship between catalytic performance and feature parameters . we\n",
      "demonstrated that the first ionization energy , bond length of tm − h\n",
      "and d band center are more correlated with hydrogen adsorption\n",
      "behaviour . our work not only predicts that fe , nb , and mo @ pc3 can\n",
      "be substitutes for pt metal in her , but also reveals that the\n",
      "intrinsic correlation between catalytic activity and feature\n",
      "parameters by combining dft and ml investigations .\n",
      "\n",
      "\n",
      "electric vehicles are gaining global popularity lately , and along\n",
      "with it , efficient battery thermal management systems ( btms ) are\n",
      "also gaining traction amongst the research community . phase change\n",
      "material ( pcm ) based btms can be an attractive solution due to its\n",
      "high energy density and isothermal energy exchange . however , pure\n",
      "pcm has some drawbacks like low thermal conductivity , volume\n",
      "expansion , and leakage during phase change . a shape stable composite\n",
      "pcm ( sscpcm ) resolves these drawbacks but is an expensive solution\n",
      "due to the high cost of conventional supporting materials . biochar (\n",
      "bc ) based sscpcm developed in this study can be a cheap and\n",
      "sustainable solution for btms . the characterization studies are\n",
      "carried out for combination of pure pcm ( myristyl alcohol ) and\n",
      "biochar at various loadings of 6 % , 12 % , 18 % , and 24 % by weight\n",
      ", using fourier transform infrared analysis ( ft-ir ) , x-ray\n",
      "diffraction ( xrd ) analysis , scanning electron microscopy ( sem ) ,\n",
      "particle size analysis ( psa ) , differential scanning calorimetry (\n",
      "dsc ) , and thermogravimetric analysis ( tga ) . the shape stability\n",
      "studies reveal that the pcm with minimum of 24 % biochar ( pcm-bc24 )\n",
      "is shape stable . the thermal conductivities and effusivities of pure\n",
      "and shape-stable composite pcms are also studied . enhancement in\n",
      "thermal conductivity of pcm-bc24 is studied with the addition of\n",
      "multi-walled carbon nanotubes ( mwcnt ) in 0.5 % and 1 %\n",
      "concentrations . ft-ir and xrd results reveal that the interaction of\n",
      "biochar and mwcnt with pure pcm is purely physical and chemically\n",
      "stable . the degree of supercooling is reduced by 19.26 % , 23.49 % ,\n",
      "and 25.17 % for pcm-bc24 with 1 % mwcnt compared to pure pcm at a\n",
      "heating rate of 5.0 , 7.5 , and 10 °c/min , respectively . thermal\n",
      "conductivity and effusivity of pcm-bc24 with 1 % mwcnt are 458.72 %\n",
      "and 146.25 % higher than the pure pcm , respectively . the tga results\n",
      "reveal that pcms thermal stability is not adversely affected by the\n",
      "addition of bc & mwcnt . furthermore , an anfis model is developed to\n",
      "predict the heat flow ( mw/mg ) values of pcm samples and found that\n",
      "the generalized bell-shaped input and linear output membership\n",
      "function is best suitable with a coefficient of determination ( r2 )\n",
      "of 0.971 .\n",
      "\n",
      "\n",
      "global solar irradiation is an important variable that can be used to\n",
      "determine the suitability of an area to install solar systems ;\n",
      "nevertheless , due to the limitations of requiring measurement\n",
      "stations around the entire world , it can be correlated with different\n",
      "meteorological parameters . to confront this issue , different\n",
      "locations in rias baixas ( autonomous community of galicia , spain )\n",
      "and combinations of parameters ( month and average temperature , among\n",
      "others ) were used to develop various machine learning models ( random\n",
      "forest -rf- , support vector machine -svm- and artificial neural\n",
      "network -ann- ) . these three approaches were used to model and\n",
      "predict ( one month ahead ) monthly global solar irradiation using the\n",
      "data from six measurement stations . afterwards , these models were\n",
      "applied to seven different measurement stations to check if the\n",
      "knowledge acquired could be extrapolated to other locations . in\n",
      "general , the ann models offered the best results for the development\n",
      "and testing phases of the model , as well as for the phase of\n",
      "knowledge extrapolation to other locations . in this sense , the\n",
      "selected anns obtained a mean absolute percentage error ( mape ) value\n",
      "between 3.9 and 13.8 % for the model development and an overall mape\n",
      "between 4.1 and 12.5 % for the other seven locations . anns can be a\n",
      "capable tool for modelling and predicting monthly global solar\n",
      "irradiation in areas where data are available and for extrapolating\n",
      "this knowledge to nearby areas .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "for file, text in tokenized_sequence:\n",
    "    print(textwrap.fill(' '.join(text)))\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a376883a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input\\file1.txt  it is essential to develop non precious metal based alternatives used \n",
      "../files/input\\file2.txt  electric vehicles are gaining global popularity lately and along with \n",
      "../files/input\\file3.txt  global solar irradiation is an important variable that can be used to \n"
     ]
    }
   ],
   "source": [
    "# Remoción de datos ruidosos (Opcion B)\n",
    "def filter_tokens_b(sequence):\n",
    "    \"\"\"Esta solucion puede perder tokens que contienen caracteres no alfabeticos\"\"\"\n",
    "    filtered_sequence = []\n",
    "    for file, tokens in sequence:\n",
    "        filtered_tokens = [re.sub(r\"[^a-zA-Z\\s]\", \" \", token) for token in tokens]\n",
    "        filtered_tokens = [re.sub(r\"\\s+\", \" \", token) for token in filtered_tokens]\n",
    "        filtered_tokens = [token.strip() for token in filtered_tokens]\n",
    "        filtered_tokens = [token for token in filtered_tokens if token != \"\"]\n",
    "        filtered_sequence.append((file, filtered_tokens))\n",
    "    return filtered_sequence\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "tokenized_sequence = tokenize(cleaned_sequence)\n",
    "filtered_sequence = filter_tokens_b(tokenized_sequence)\n",
    "for file, text in filtered_sequence:\n",
    "    print(f\"{file}  {' '.join(text)[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cec09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "\n",
    "def remove_stopwords(sequence):\n",
    "    stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    filtered_sequence = []\n",
    "    for file, tokens in sequence:\n",
    "        filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "        filtered_sequence.append((file, filtered_tokens))\n",
    "    return filtered_sequence\n",
    "\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "tokenized_sequence = tokenize(cleaned_sequence)\n",
    "filtered_sequence = filter_tokens_b(tokenized_sequence)\n",
    "filtered_sequence = remove_stopwords(filtered_sequence)\n",
    "for file, text in filtered_sequence:\n",
    "    print(f\"{file}  {' '.join(text)[:70]}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ea049",
   "metadata": {},
   "outputs": [],
   "source": [
    "## country_scientific_production.py\n",
    "\n",
    "\n",
    "\"\"\"Taller Presencial Evaluable\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import folium  # type: ignore\n",
    "import pandas as pd  # type: ignore\n",
    "\n",
    "\n",
    "def load_affiliations():\n",
    "    \"\"\"Carga el archivo scopus-papers.csv y retorna un dataframe con la\n",
    "    columna 'Affiliations'\"\"\"\n",
    "\n",
    "    dataframe = pd.read_csv(\n",
    "        (\n",
    "            \"https://raw.githubusercontent.com/jdvelasq/datalabs/\"\n",
    "            \"master/datasets/scopus-papers.csv\"\n",
    "        ),\n",
    "        sep=\",\",\n",
    "        index_col=None,\n",
    "    )[[\"Affiliations\"]]\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def remove_na_rows(affiliations):\n",
    "    \"\"\"Elimina las filas con valores nulos en la columna 'Affiliations'\"\"\"\n",
    "\n",
    "    affiliations = affiliations.copy()\n",
    "    affiliations = affiliations.dropna(subset=[\"Affiliations\"])\n",
    "\n",
    "    return affiliations\n",
    "\n",
    "\n",
    "def add_countries_column(affiliations):\n",
    "    \"\"\"Transforma la columna 'Affiliations' a una lista de paises.\"\"\"\n",
    "\n",
    "    affiliations = affiliations.copy()\n",
    "    affiliations[\"countries\"] = affiliations[\"Affiliations\"].copy()\n",
    "    affiliations[\"countries\"] = affiliations[\"countries\"].str.split(\";\")\n",
    "    affiliations[\"countries\"] = affiliations[\"countries\"].map(\n",
    "        lambda x: [y.split(\",\") for y in x]\n",
    "    )\n",
    "    affiliations[\"countries\"] = affiliations[\"countries\"].map(\n",
    "        lambda x: [y[-1].strip() for y in x]\n",
    "    )\n",
    "    affiliations[\"countries\"] = affiliations[\"countries\"].map(set)\n",
    "    affiliations[\"countries\"] = affiliations[\"countries\"].str.join(\", \")\n",
    "\n",
    "    return affiliations\n",
    "\n",
    "\n",
    "def clean_countries(affiliations):\n",
    "\n",
    "    affiliations = affiliations.copy()\n",
    "    affiliations[\"countries\"] = affiliations[\"countries\"].str.replace(\n",
    "        \"United States\", \"United States of America\"\n",
    "    )\n",
    "    return affiliations\n",
    "\n",
    "\n",
    "def count_country_frequency(affiliations):\n",
    "    \"\"\"Cuenta la frecuencia de cada país en la columna 'countries'\"\"\"\n",
    "\n",
    "    countries = affiliations[\"countries\"].copy()\n",
    "    countries = countries.str.split(\", \")\n",
    "    countries = countries.explode()\n",
    "    countries = countries.value_counts()\n",
    "    return countries\n",
    "\n",
    "\n",
    "def plot_world_map(countries):\n",
    "    \"\"\"Grafica un mapa mundial con la frecuencia de cada país.\"\"\"\n",
    "\n",
    "    countries = countries.copy()\n",
    "    countries = countries.to_frame()\n",
    "    countries = countries.reset_index()\n",
    "\n",
    "    m = folium.Map(location=[0, 0], zoom_start=2)\n",
    "\n",
    "    folium.Choropleth(\n",
    "        geo_data=(\n",
    "            \"https://raw.githubusercontent.com/python-visualization/\"\n",
    "            \"folium/master/examples/data/world-countries.json\"\n",
    "        ),\n",
    "        data=countries,\n",
    "        columns=[\"countries\", \"count\"],\n",
    "        key_on=\"feature.properties.name\",\n",
    "        fill_color=\"Greens\",\n",
    "    ).add_to(m)\n",
    "\n",
    "    m.save(\"files/map.html\")\n",
    "\n",
    "\n",
    "def make_worldmap():\n",
    "    \"\"\"Función principal\"\"\"\n",
    "\n",
    "    if not os.path.exists(\"files\"):\n",
    "        os.makedirs(\"files\")\n",
    "\n",
    "    affiliations = load_affiliations()\n",
    "    affiliations = remove_na_rows(affiliations)\n",
    "    affiliations = add_countries_column(affiliations)\n",
    "    affiliations = clean_countries(affiliations)\n",
    "    countries = count_country_frequency(affiliations)\n",
    "    countries.to_csv(\"files/countries.csv\")\n",
    "    plot_world_map(countries)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    make_worldmap()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
